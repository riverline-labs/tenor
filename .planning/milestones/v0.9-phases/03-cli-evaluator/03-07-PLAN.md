---
phase: 03-cli-evaluator
plan: 07
type: execute
wave: 1
depends_on: []
files_modified:
  - conformance/eval/numeric/int_promotion.tenor
  - conformance/eval/numeric/int_promotion.facts.json
  - conformance/eval/numeric/int_promotion.verdicts.json
  - conformance/eval/numeric/decimal_rounding.tenor
  - conformance/eval/numeric/decimal_rounding.facts.json
  - conformance/eval/numeric/decimal_rounding.verdicts.json
  - conformance/eval/numeric/money_comparison.tenor
  - conformance/eval/numeric/money_comparison.facts.json
  - conformance/eval/numeric/money_comparison.verdicts.json
  - conformance/eval/numeric/decimal_overflow.tenor
  - conformance/eval/numeric/decimal_overflow.facts.json
  - conformance/eval/numeric/decimal_overflow.verdicts.json
  - crates/eval/tests/conformance.rs
  - .planning/REQUIREMENTS.md
autonomous: true
gap_closure: true
requirements:
  - EVAL-05
  - EVAL-06
  - EVAL-07
  - TEST-09
  - CLI-01
  - CLI-02
  - CLI-03
  - CLI-05
  - CLI-07
  - CLI-09
  - EVAL-01
  - EVAL-02
  - EVAL-03
  - EVAL-04
  - TEST-07
  - MIGR-01

must_haves:
  truths:
    - "File-based numeric fixtures exist in conformance/eval/numeric/ covering promotion, rounding, overflow, and money"
    - "Evaluator conformance runner discovers and executes numeric/ directory fixtures alongside positive/ and frozen/"
    - "REQUIREMENTS.md accurately reflects the implementation status of EVAL-05, EVAL-06, EVAL-07, TEST-09"
    - "All existing tests continue to pass (no regressions)"
  artifacts:
    - path: "conformance/eval/numeric/int_promotion.tenor"
      provides: "Int-to-Decimal promotion test via DSL"
    - path: "conformance/eval/numeric/decimal_rounding.tenor"
      provides: "MidpointNearestEven banker's rounding test via DSL"
    - path: "conformance/eval/numeric/money_comparison.tenor"
      provides: "Money comparison test via DSL"
    - path: "conformance/eval/numeric/decimal_overflow.tenor"
      provides: "Decimal overflow detection test via DSL"
    - path: "crates/eval/tests/conformance.rs"
      provides: "Updated conformance runner with numeric/ directory support"
    - path: ".planning/REQUIREMENTS.md"
      provides: "Updated requirement statuses for EVAL-05, EVAL-06, EVAL-07, TEST-09"
  key_links:
    - from: "crates/eval/tests/conformance.rs"
      to: "conformance/eval/numeric/"
      via: "numeric_dir() path helper + test functions"
      pattern: "run_eval_fixture.*numeric_dir"
---

<objective>
Close two verification gaps from Phase 3 VERIFICATION.md:

1. **TEST-09 gap**: Create file-based fixture triplets in `conformance/eval/numeric/` for key numeric categories (promotion, rounding, overflow, money) that the evaluator conformance runner can consume. This fulfills the original plan's intent for file-based numeric fixtures and enables future cross-suite sharing.

2. **REQUIREMENTS.md gap**: Update requirement statuses for EVAL-05, EVAL-06, EVAL-07 (mark Complete) and TEST-09 (mark Complete with note about dual-approach coverage).

Purpose: Close the last verification gap so Phase 3 reaches 20/20 must-haves and can be marked Complete.
Output: 4 numeric fixture triplets, updated conformance runner, updated REQUIREMENTS.md
</objective>

<execution_context>
@/Users/bwb/.claude/get-shit-done/workflows/execute-plan.md
@/Users/bwb/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/phases/03-cli-evaluator/03-VERIFICATION.md
@.planning/phases/03-cli-evaluator/03-06-SUMMARY.md
@crates/eval/tests/conformance.rs
@conformance/eval/positive/fact_decimal_basic.tenor
@conformance/eval/positive/fact_decimal_basic.facts.json
@conformance/eval/positive/fact_decimal_basic.verdicts.json
@conformance/eval/positive/fact_money_basic.tenor
@conformance/eval/positive/fact_money_basic.facts.json
@conformance/eval/positive/fact_money_basic.verdicts.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create file-based numeric precision fixtures and wire conformance runner</name>
  <files>
    conformance/eval/numeric/int_promotion.tenor
    conformance/eval/numeric/int_promotion.facts.json
    conformance/eval/numeric/int_promotion.verdicts.json
    conformance/eval/numeric/decimal_rounding.tenor
    conformance/eval/numeric/decimal_rounding.facts.json
    conformance/eval/numeric/decimal_rounding.verdicts.json
    conformance/eval/numeric/money_comparison.tenor
    conformance/eval/numeric/money_comparison.facts.json
    conformance/eval/numeric/money_comparison.verdicts.json
    conformance/eval/numeric/decimal_overflow.tenor
    conformance/eval/numeric/decimal_overflow.facts.json
    conformance/eval/numeric/decimal_overflow.verdicts.json
    crates/eval/tests/conformance.rs
  </files>
  <action>
    Create 4 file-based fixture triplets in `conformance/eval/numeric/` covering the key numeric categories from spec Section 12 (NumericModel). Follow the exact same convention as `conformance/eval/positive/` fixtures: `.tenor` + `.facts.json` + `.verdicts.json`.

    **Fixture 1: int_promotion** (Int-to-Decimal promotion, spec Section 12.2)
    - `.tenor`: Two facts — one Int, one Decimal(10,2). A rule comparing them with `>` operator. This tests that the evaluator promotes the Int to Decimal before comparison.
    - `.facts.json`: Int value like 150, Decimal value like "100.00"
    - `.verdicts.json`: Verdict produced (comparison succeeds after promotion)

    **Fixture 2: decimal_rounding** (MidpointNearestEven / banker's rounding)
    - `.tenor`: Two Decimal facts with different scales — one Decimal(10,1), one Decimal(10,0). Rule comparing them with `=` using a comparison_type that forces rounding.
    - `.facts.json`: Value "2.5" for the scale-1 fact, "2" for the scale-0 fact (2.5 rounds to 2 with banker's rounding, not 3)
    - `.verdicts.json`: Verdict produced (banker's rounding correctly rounds 2.5 to even digit 2)
    - **Critical**: This tests MidpointNearestEven specifically. 2.5 -> 2 (rounds down to even), NOT 3. This is the key spec NumericModel requirement.

    **Fixture 3: money_comparison** (Money cross-comparison)
    - `.tenor`: Two Money(currency: "USD") facts. Rule comparing with `<=`.
    - `.facts.json`: Values like {"amount": "999.99", "currency": "USD"} and {"amount": "1000.00", "currency": "USD"}
    - `.verdicts.json`: Verdict produced (999.99 <= 1000.00)

    **Fixture 4: decimal_overflow** (Overflow detection — error case)
    - `.tenor`: A Decimal(5,2) fact with a Mul rule that would overflow the declared precision. Use `fact * 10000` where the result cannot fit in Decimal(5,2).
    - `.facts.json`: A value like "999.99" that when multiplied would exceed declared precision
    - No `.verdicts.json` — this is an error case. The evaluator should return an error.

    Then update `crates/eval/tests/conformance.rs`:
    - Add a `numeric_dir()` helper function following the same pattern as `positive_dir()` and `frozen_dir()`:
      ```rust
      fn numeric_dir() -> PathBuf {
          PathBuf::from(env!("CARGO_MANIFEST_DIR"))
              .parent().unwrap().parent().unwrap()
              .join("conformance").join("eval").join("numeric")
      }
      ```
    - Add test functions for each fixture:
      ```rust
      #[test]
      fn numeric_int_promotion() {
          run_eval_fixture(&numeric_dir(), "int_promotion");
      }
      ```
    - For the overflow error case, use `run_eval_fixture_error()`.

    **Important DSL conventions** (from CLAUDE.md):
    - All DSL keywords are lowercase: `fact`, `rule`, `type`, `source`
    - Money type syntax: `Money(currency: "USD")`
    - Decimal type syntax: `Decimal(precision: 10, scale: 2)`
    - Int type syntax: `Int(min: 0, max: 1000)`

    To generate the expected `.verdicts.json` files, first elaborate each .tenor file with `cargo run -p tenor-cli -- elaborate <file.tenor>`, then manually evaluate or use the evaluator to generate verdicts, matching the exact format of existing verdicts in `conformance/eval/positive/`. If unsure about exact output, run the evaluator and capture the actual output to use as expected.
  </action>
  <verify>
    ```bash
    # All existing tests still pass
    cargo test --workspace

    # New numeric fixtures are discovered and pass
    cargo test -p tenor-eval --test conformance numeric_
    ```
  </verify>
  <done>
    4 file-based fixture triplets exist in `conformance/eval/numeric/` (12 files for the 3 positive cases + 2 files for the error case = 14 total files). The evaluator conformance runner discovers and executes them. All pass alongside existing 20 conformance tests and 61 numeric regression tests.
  </done>
</task>

<task type="auto">
  <name>Task 2: Update REQUIREMENTS.md with correct statuses for Phase 3 evaluator requirements</name>
  <files>
    .planning/REQUIREMENTS.md
  </files>
  <action>
    Update `.planning/REQUIREMENTS.md` to reflect the actual implementation status:

    1. **EVAL-05** (line 44): Change `[ ]` to `[x]` — "Evaluator conformance suite with dedicated test fixtures". Evidence: 20 conformance tests pass across positive/, frozen/, and now numeric/ directories.

    2. **EVAL-06** (line 45): Change `[ ]` to `[x]` — "Evaluator conformance suite includes frozen verdict semantics edge cases". Evidence: 3 frozen verdict fixtures (flow_frozen_verdicts, flow_frozen_facts, flow_subflow_snapshot) all pass.

    3. **EVAL-07** (line 46): Change `[ ]` to `[x]` — "Evaluator conformance suite includes numeric precision edge cases (50+ cases)". Evidence: 61 code-based numeric regression tests + 4 file-based numeric fixtures in conformance/eval/numeric/.

    4. **TEST-09** (line 101): Change `[ ]` to `[x]` — "Numeric precision regression suite shared across elaborator, evaluator, and codegen targets". Evidence: Elaborator has file fixtures in `conformance/numeric/`, evaluator has 61 code-based tests + file fixtures in `conformance/eval/numeric/`, both cover spec Section 12 NumericModel. Codegen target coverage deferred to Phase 6/7 as expected.

    5. In the **Traceability** table at the bottom, update these rows:
       - `EVAL-05 | Phase 3 | Pending` → `EVAL-05 | Phase 3 | Complete`
       - `EVAL-06 | Phase 3 | Pending` → `EVAL-06 | Phase 3 | Complete`
       - `EVAL-07 | Phase 3 | Pending` → `EVAL-07 | Phase 3 | Complete`
       - `TEST-09 | Phase 3 | Pending` → `TEST-09 | Phase 3 | Complete`

    Do NOT change any other requirements or statuses.
  </action>
  <verify>
    ```bash
    # Verify checkboxes updated
    grep -n "EVAL-05\|EVAL-06\|EVAL-07\|TEST-09" .planning/REQUIREMENTS.md
    ```
  </verify>
  <done>
    EVAL-05, EVAL-06, EVAL-07 marked `[x]` in the requirements list. TEST-09 marked `[x]`. Traceability table shows all four as Complete. No other requirements modified.
  </done>
</task>

</tasks>

<verification>
```bash
# 1. All workspace tests pass (no regressions)
cargo test --workspace

# 2. New numeric conformance fixtures pass
cargo test -p tenor-eval --test conformance numeric_

# 3. Existing conformance and regression tests still pass
cargo test -p tenor-eval --test conformance
cargo test -p tenor-eval --test numeric_regression

# 4. Elaborator conformance still passes
cargo run -p tenor-cli -- test conformance

# 5. REQUIREMENTS.md shows correct statuses
grep "EVAL-05" .planning/REQUIREMENTS.md | grep "\[x\]"
grep "EVAL-06" .planning/REQUIREMENTS.md | grep "\[x\]"
grep "EVAL-07" .planning/REQUIREMENTS.md | grep "\[x\]"
grep "TEST-09" .planning/REQUIREMENTS.md | grep "\[x\]"
```
</verification>

<success_criteria>
1. `conformance/eval/numeric/` contains 4 fixture triplets (14 files total) covering int promotion, decimal rounding, money comparison, and overflow detection
2. `crates/eval/tests/conformance.rs` has `numeric_dir()` helper and 4 new test functions
3. All 4 new numeric conformance tests pass
4. All existing 20 conformance tests + 61 numeric regression tests still pass
5. REQUIREMENTS.md shows EVAL-05, EVAL-06, EVAL-07, TEST-09 as Complete
6. Elaborator 55/55 conformance still passes (no regressions)
</success_criteria>

<output>
After completion, create `.planning/phases/03-cli-evaluator/03-07-SUMMARY.md`
</output>
