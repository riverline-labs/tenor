---
phase: 01.1-spec-ci-ai-ambiguity-testing
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - elaborator/Cargo.toml
  - elaborator/src/ambiguity/mod.rs
  - elaborator/src/ambiguity/api.rs
  - elaborator/src/ambiguity/prompt.rs
  - elaborator/src/ambiguity/compare.rs
  - elaborator/src/ambiguity/report.rs
  - elaborator/src/ambiguity/fixtures.rs
  - conformance/ambiguity/rule_basic_all_satisfied.facts.json
  - conformance/ambiguity/rule_basic_partial.facts.json
  - conformance/ambiguity/rule_basic_none.facts.json
  - conformance/ambiguity/rule_basic_all_satisfied.verdicts.json
  - conformance/ambiguity/rule_basic_partial.verdicts.json
  - conformance/ambiguity/rule_basic_none.verdicts.json
  - conformance/ambiguity/escrow_release_approved.facts.json
  - conformance/ambiguity/escrow_refund_approved.facts.json
  - conformance/ambiguity/escrow_compliance_required.facts.json
  - conformance/ambiguity/escrow_release_approved.verdicts.json
  - conformance/ambiguity/escrow_refund_approved.verdicts.json
  - conformance/ambiguity/escrow_compliance_required.verdicts.json
  - conformance/ambiguity/mul_valid_satisfied.facts.json
  - conformance/ambiguity/mul_valid_not_satisfied.facts.json
  - conformance/ambiguity/mul_valid_satisfied.verdicts.json
  - conformance/ambiguity/mul_valid_not_satisfied.verdicts.json
autonomous: true
requirements:
  - SPEC-05

must_haves:
  truths:
    - "ureq HTTP client can POST to Anthropic Messages API and deserialize the response into typed Rust structs"
    - "Verdict comparison produces symmetric set difference showing missing and extra verdicts"
    - "Report output emits TAP-format lines with ambiguity metadata for each test case"
    - "Prompt builder injects relevant spec sections, contract source, facts, and evaluation instructions into a structured prompt"
    - "Synthetic fact sets cover all-satisfied, partial, and none-satisfied scenarios for each rule-bearing contract"
    - "Fixture loader reads .tenor source, .facts.json, and .verdicts.json triplets from conformance/ambiguity/"
  artifacts:
    - path: "elaborator/src/ambiguity/api.rs"
      provides: "Anthropic Messages API client with retry and rate-limit handling"
      contains: "fn call_anthropic"
    - path: "elaborator/src/ambiguity/prompt.rs"
      provides: "Prompt construction from spec sections + contract + facts"
      contains: "fn build_prompt"
    - path: "elaborator/src/ambiguity/compare.rs"
      provides: "Verdict set comparison with symmetric difference"
      contains: "fn compare_verdicts"
    - path: "elaborator/src/ambiguity/report.rs"
      provides: "TAP-format ambiguity reporting"
      contains: "fn report_result"
    - path: "elaborator/src/ambiguity/fixtures.rs"
      provides: "Test case loader for ambiguity fixtures"
      contains: "fn load_test_cases"
    - path: "conformance/ambiguity/rule_basic_all_satisfied.facts.json"
      provides: "Fact set where all rule_basic rules fire"
    - path: "conformance/ambiguity/escrow_release_approved.facts.json"
      provides: "Fact set where escrow release path fires"
  key_links:
    - from: "elaborator/src/ambiguity/api.rs"
      to: "https://api.anthropic.com/v1/messages"
      via: "ureq POST with x-api-key header"
      pattern: "ureq::post.*api.anthropic.com"
    - from: "elaborator/src/ambiguity/fixtures.rs"
      to: "conformance/ambiguity/*.facts.json"
      via: "file system glob + serde_json deserialization"
      pattern: "load_test_cases"
    - from: "elaborator/src/ambiguity/prompt.rs"
      to: "docs/TENOR.md"
      via: "spec section extraction by line range or heading"
      pattern: "build_prompt"
---

<objective>
Build all core modules for the AI ambiguity testing harness: the Anthropic API client, prompt builder, verdict comparison engine, fixture loader, TAP reporter, and the synthetic test cases with manually-derived ground truth.

Purpose: These modules form the complete data pipeline for the ambiguity harness -- from loading test fixtures, constructing prompts, calling the LLM, comparing results, to reporting findings. Plan 02 will wire these into an orchestrator and CLI subcommand.

Output: Six Rust source modules under `elaborator/src/ambiguity/` and 14 fixture files (facts + expected verdicts) under `conformance/ambiguity/`.
</objective>

<execution_context>
@/Users/bwb/.claude/get-shit-done/workflows/execute-plan.md
@/Users/bwb/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01.1-spec-ci-ai-ambiguity-testing/01.1-RESEARCH.md
@elaborator/Cargo.toml
@elaborator/src/main.rs
@elaborator/src/runner.rs
@elaborator/src/tap.rs
@conformance/positive/rule_basic.tenor
@conformance/positive/rule_basic.expected.json
@conformance/positive/integration_escrow.tenor
@conformance/positive/rule_mul_valid.tenor
@docs/TENOR.md (Sections 4, 7, 10, 12 — rule evaluation semantics)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build API client, verdict comparator, and TAP reporter modules</name>
  <files>
    elaborator/Cargo.toml
    elaborator/src/ambiguity/mod.rs
    elaborator/src/ambiguity/api.rs
    elaborator/src/ambiguity/compare.rs
    elaborator/src/ambiguity/report.rs
  </files>
  <action>
**Cargo.toml changes:** Add `ureq = { version = "3", features = ["json"] }` to `[dependencies]`. serde and serde_json are already present. After adding, run `cargo tree | grep tokio` to verify no async runtime was pulled in.

**elaborator/src/ambiguity/mod.rs:** Create module file that declares submodules: `pub mod api; pub mod prompt; pub mod compare; pub mod report; pub mod fixtures;`. Also define shared types used across modules:

```rust
pub struct AmbiguityTestCase {
    pub name: String,
    pub contract_source: String,     // .tenor file contents
    pub facts: serde_json::Value,    // fact values as JSON object
    pub expected_verdicts: Vec<String>, // sorted verdict IDs
    pub spec_sections: Vec<String>,  // relevant spec section text
}

pub struct AmbiguityResult {
    pub test_name: String,
    pub expected_verdicts: BTreeSet<String>,
    pub llm_verdicts: BTreeSet<String>,
    pub llm_reasoning: String,
    pub ambiguities_noted: Vec<String>,
    pub confidence: String,
}
```

**elaborator/src/ambiguity/api.rs:** Implement the Anthropic Messages API client using ureq. Key elements:
- Constant `ANTHROPIC_API_URL = "https://api.anthropic.com/v1/messages"`
- Constant `ANTHROPIC_VERSION = "2023-06-01"`
- Serde structs for request (`MessagesRequest` with model, max_tokens, system, messages) and response (`MessagesResponse` with content blocks, stop_reason)
- `fn call_anthropic(api_key: &str, system: &str, user_prompt: &str, model: &str) -> Result<String, String>` -- sends POST with x-api-key, anthropic-version, content-type headers. Returns the text from content[0].
- `fn with_retry<T, F: Fn() -> Result<T, String>>(f: F, max_retries: u32) -> Result<T, String>` -- exponential backoff starting at 1000ms, doubling each retry. Retries on 429, 500, 503 errors only.
- `fn is_retryable(error: &str) -> bool` -- checks for rate limit and server error codes.
- Default model: `"claude-sonnet-4-5-20250514"`. Accept model as parameter so it can be overridden.
- Read API key from `ANTHROPIC_API_KEY` environment variable. Return clear error if missing.

**elaborator/src/ambiguity/compare.rs:** Implement verdict set comparison:
- `fn compare_verdicts(expected: &[String], actual: &[String]) -> VerdictComparison` where `VerdictComparison` has `is_match: bool`, `missing: BTreeSet<String>` (in expected but not actual), `extra: BTreeSet<String>` (in actual but not expected).
- `fn parse_llm_response(response_text: &str) -> Result<LlmVerdictResponse, String>` -- parse JSON from the LLM's response text. The expected schema is `{"verdicts_produced": [...], "reasoning": "...", "confidence": "high|medium|low", "ambiguities_noted": [...]}`. Use serde_json::from_str. If the LLM wraps JSON in markdown code fences, strip them first.

**elaborator/src/ambiguity/report.rs:** TAP-format reporting following the existing pattern in `tap.rs`:
- `struct AmbiguityReport` with a `Vec<AmbiguityResult>` and methods:
  - `fn add_result(&mut self, result: AmbiguityResult)`
  - `fn print_tap(&self)` -- prints TAP output where matches are "ok" and mismatches are "not ok" with diagnostic lines showing missing/extra verdicts and LLM reasoning excerpt
  - `fn summary(&self) -> (usize, usize, usize)` -- returns (total, matches, mismatches)
  - `fn ambiguity_signals(&self) -> Vec<&AmbiguityResult>` -- returns only mismatched results for investigation

Use the same TAP style as `tap.rs` (1..N header, ok/not ok lines, # diagnostic comments). Add YAML diagnostic blocks for mismatches showing: missing_verdicts, extra_verdicts, llm_confidence, ambiguities_noted.
  </action>
  <verify>
`cd /Users/bwb/src/rll/tenor/elaborator && cargo build` succeeds. `cargo tree | grep tokio` returns empty (no async runtime). The `ambiguity` module compiles without warnings.
  </verify>
  <done>
API client, verdict comparator, and TAP reporter modules compile. ureq is the HTTP dependency with no tokio. Shared types are defined in mod.rs. API client supports retry with exponential backoff. Comparator produces symmetric set difference. Reporter emits TAP with YAML diagnostics for mismatches.
  </done>
</task>

<task type="auto">
  <name>Task 2: Build prompt constructor, fixture loader, and synthetic test cases</name>
  <files>
    elaborator/src/ambiguity/prompt.rs
    elaborator/src/ambiguity/fixtures.rs
    conformance/ambiguity/rule_basic_all_satisfied.facts.json
    conformance/ambiguity/rule_basic_partial.facts.json
    conformance/ambiguity/rule_basic_none.facts.json
    conformance/ambiguity/rule_basic_all_satisfied.verdicts.json
    conformance/ambiguity/rule_basic_partial.verdicts.json
    conformance/ambiguity/rule_basic_none.verdicts.json
    conformance/ambiguity/escrow_release_approved.facts.json
    conformance/ambiguity/escrow_refund_approved.facts.json
    conformance/ambiguity/escrow_compliance_required.facts.json
    conformance/ambiguity/escrow_release_approved.verdicts.json
    conformance/ambiguity/escrow_refund_approved.verdicts.json
    conformance/ambiguity/escrow_compliance_required.verdicts.json
    conformance/ambiguity/mul_valid_satisfied.facts.json
    conformance/ambiguity/mul_valid_not_satisfied.facts.json
    conformance/ambiguity/mul_valid_satisfied.verdicts.json
    conformance/ambiguity/mul_valid_not_satisfied.verdicts.json
  </files>
  <action>
**elaborator/src/ambiguity/prompt.rs:** Build the prompt constructor that layers spec + contract + facts + question.

- `fn build_system_prompt(spec_path: &Path) -> Result<String, String>` -- reads `docs/TENOR.md` and extracts Sections 4 (BaseType/TypeDecl), 7 (Rule), 10 (PredicateExpression), and 12 (NumericModel). Extract by finding `## N.` or `## N ` section headings and capturing until the next `## M.` heading at the same level. The system prompt template is:

```
You are a Tenor specification evaluator. Given the spec sections below,
a Tenor contract, and a set of fact values, determine which verdicts are
produced by evaluating the contract's rules against the facts.
Follow the specification text EXACTLY. Do not infer rules beyond what the
spec states. Show your reasoning step by step.

[Extracted spec sections]
```

- `fn build_user_prompt(contract_source: &str, facts: &serde_json::Value) -> String` -- constructs:

```
## Contract
[contract source]

## Fact Values
[pretty-printed facts JSON]

## Instructions
Evaluate all rules in this contract against the provided fact values.
For each rule, evaluate its `when` condition using the spec's PredicateExpression
evaluation rules. If the condition is satisfied, the rule produces its declared verdict.
Rules are evaluated in stratum order (stratum 0 first, then stratum 1).
A stratum 1 rule can reference verdicts produced by stratum 0 rules via verdict_present().

Return your response as JSON with this exact schema:
{
  "verdicts_produced": ["verdict_id_1", "verdict_id_2"],
  "reasoning": "step-by-step evaluation trace",
  "confidence": "high|medium|low",
  "ambiguities_noted": ["any unclear spec areas encountered"]
}
```

- `fn extract_spec_sections(spec_text: &str, sections: &[u32]) -> String` -- given spec text and section numbers (e.g., [4, 7, 10, 12]), extracts those top-level sections. Parse by looking for lines matching `^## {N}[. ]` and collecting until the next `^## {M}[. ]` where M != N.

**elaborator/src/ambiguity/fixtures.rs:** Load test cases from the conformance/ambiguity/ directory.

- `fn load_test_cases(ambiguity_dir: &Path, contract_dir: &Path) -> Result<Vec<AmbiguityTestCase>, String>` -- scans ambiguity_dir for `*.facts.json` files. For each, derives:
  - The contract name from the filename prefix (e.g., `rule_basic_all_satisfied` -> contract `rule_basic`)
  - Loads the contract source from `contract_dir/positive/{contract_name}.tenor` (or `contract_dir/promotion/{contract_name}.tenor` etc.)
  - Loads facts from the `.facts.json` file
  - Loads expected verdicts from the matching `.verdicts.json` file
  - The spec_sections field defaults to [4, 7, 10, 12] for all test cases

Convention: facts files are named `{contract}_{scenario}.facts.json` where `{contract}` matches a `.tenor` file in the conformance positive directory and `{scenario}` describes the fact set variant. The verdicts file has the matching name `{contract}_{scenario}.verdicts.json`.

Add a mapping file or constant that maps fixture prefixes to their conformance subdirectory:
```rust
fn contract_dir_for(name: &str) -> &str {
    match name {
        "rule_basic" | "integration_escrow" => "positive",
        "rule_mul_valid" => "positive",
        _ => "positive",  // default
    }
}
```

**Synthetic test cases -- create all 14 fixture files:**

**rule_basic (3 scenarios):**

1. `rule_basic_all_satisfied.facts.json`:
```json
{
  "is_active": true,
  "balance": { "amount": "500.00", "currency": "USD" },
  "credit_limit": { "amount": "1000.00", "currency": "USD" },
  "line_items": [
    { "amount": { "amount": "100.00", "currency": "USD" }, "approved": true },
    { "amount": { "amount": "200.00", "currency": "USD" }, "approved": true }
  ]
}
```
Verdicts: `["account_active", "all_items_approved", "order_processable", "within_credit_limit"]` (sorted)

2. `rule_basic_partial.facts.json`:
```json
{
  "is_active": true,
  "balance": { "amount": "1500.00", "currency": "USD" },
  "credit_limit": { "amount": "1000.00", "currency": "USD" },
  "line_items": [
    { "amount": { "amount": "100.00", "currency": "USD" }, "approved": true },
    { "amount": { "amount": "200.00", "currency": "USD" }, "approved": false }
  ]
}
```
Verdicts: `["account_active"]` (is_active=true fires account_active; balance > credit_limit so within_credit_limit does NOT fire; one item not approved so all_items_approved does NOT fire; stratum 1 can_process_order requires all three so does NOT fire)

3. `rule_basic_none.facts.json`:
```json
{
  "is_active": false,
  "balance": { "amount": "2000.00", "currency": "USD" },
  "credit_limit": { "amount": "1000.00", "currency": "USD" },
  "line_items": [
    { "amount": { "amount": "100.00", "currency": "USD" }, "approved": false }
  ]
}
```
Verdicts: `[]` (no stratum 0 rules fire, so no stratum 1 rules fire)

**integration_escrow (3 scenarios):**

4. `escrow_release_approved.facts.json`:
```json
{
  "escrow_amount": { "amount": "5000.00", "currency": "USD" },
  "delivery_status": "confirmed",
  "line_items": [
    { "id": "item1", "description": "Widget A", "amount": { "amount": "5000.00", "currency": "USD" }, "valid": true }
  ],
  "compliance_threshold": { "amount": "10000.00", "currency": "USD" },
  "buyer_requested_refund": false
}
```
Verdicts: `["delivery_confirmed", "line_items_validated", "release_approved", "within_threshold"]` (sorted). Stratum 0: delivery_status="confirmed" fires delivery_confirmed, all valid fires line_items_validated, 5000<=10000 fires within_threshold, refund=false so refund_requested does NOT fire, delivery_status != "failed" so delivery_failed does NOT fire. Stratum 1: line_items_validated AND delivery_confirmed AND within_threshold all present so can_release_without_compliance fires release_approved. requires_compliance_review needs NOT within_threshold which is false. can_refund needs delivery_failed which is absent.

5. `escrow_refund_approved.facts.json`:
```json
{
  "escrow_amount": { "amount": "5000.00", "currency": "USD" },
  "delivery_status": "failed",
  "line_items": [
    { "id": "item1", "description": "Widget A", "amount": { "amount": "5000.00", "currency": "USD" }, "valid": true }
  ],
  "compliance_threshold": { "amount": "10000.00", "currency": "USD" },
  "buyer_requested_refund": true
}
```
Verdicts: `["delivery_failed", "line_items_validated", "refund_approved", "refund_requested", "within_threshold"]` (sorted). Stratum 0: delivery_status="failed" fires delivery_failed, all valid fires line_items_validated, 5000<=10000 fires within_threshold, refund=true fires refund_requested. Stratum 1: can_release needs delivery_confirmed (absent), requires_compliance needs delivery_confirmed (absent), can_refund needs delivery_failed AND refund_requested (both present) so fires refund_approved.

6. `escrow_compliance_required.facts.json`:
```json
{
  "escrow_amount": { "amount": "15000.00", "currency": "USD" },
  "delivery_status": "confirmed",
  "line_items": [
    { "id": "item1", "description": "Widget A", "amount": { "amount": "15000.00", "currency": "USD" }, "valid": true }
  ],
  "compliance_threshold": { "amount": "10000.00", "currency": "USD" },
  "buyer_requested_refund": false
}
```
Verdicts: `["compliance_review_required", "delivery_confirmed", "line_items_validated"]` (sorted). Stratum 0: delivery_confirmed fires, line_items_validated fires, 15000 > 10000 so within_threshold does NOT fire. Stratum 1: can_release needs within_threshold (absent), requires_compliance needs line_items_validated AND delivery_confirmed AND NOT within_threshold -- all true, fires compliance_review_required. can_refund needs delivery_failed (absent).

**rule_mul_valid (2 scenarios):**

7. `mul_valid_satisfied.facts.json`:
```json
{
  "x": 5
}
```
Verdicts: `["scaled_x"]` (x=5 > 0 fires rule, verdict payload is x*10=50)

8. `mul_valid_not_satisfied.facts.json`:
```json
{
  "x": 0
}
```
Verdicts: `[]` (x=0, condition x > 0 is false, rule does not fire)

Each `.verdicts.json` file is a JSON object: `{"verdicts": ["sorted", "list", "of", "verdict_ids"]}`.
  </action>
  <verify>
`cd /Users/bwb/src/rll/tenor/elaborator && cargo build` succeeds. All 14 fixture files exist in `conformance/ambiguity/`. Each `.facts.json` is valid JSON. Each `.verdicts.json` is valid JSON with a `verdicts` array. Fixture loader can be tested with a quick unit test: `cargo test -- ambiguity` (if unit tests are added, or just verify the module compiles).
  </verify>
  <done>
Prompt builder constructs layered prompts with spec sections, contract source, facts, and evaluation instructions. Fixture loader reads .tenor/.facts.json/.verdicts.json triplets. 8 synthetic test cases across 3 contracts (rule_basic x3, integration_escrow x3, rule_mul_valid x2) cover all-satisfied, partial, and none-satisfied scenarios. Ground truth manually derived from spec and contract logic.
  </done>
</task>

</tasks>

<verification>
- `cd elaborator && cargo build` compiles cleanly with no warnings
- `cargo tree | grep tokio` returns empty (no async runtime introduced)
- All 6 Rust source files exist under `elaborator/src/ambiguity/`
- All 14 fixture files exist under `conformance/ambiguity/` (8 facts + 8 verdicts — wait, 8 facts but we have some scenarios that share... actually we have exactly 8 .facts.json and 8 .verdicts.json = 16 files)
- Each `.facts.json` file is parseable by `serde_json`
- Each `.verdicts.json` file has a `verdicts` array of strings
- The elaborator's existing 47 conformance tests still pass: `cd elaborator && cargo run -- run ../conformance` reports 47/47
</verification>

<success_criteria>
The ambiguity harness core modules are built and compilable. The synthetic test cases have manually-derived ground truth covering stratum 0 rules (scalar comparison, enum comparison, Money comparison, bounded quantification), stratum 1 rules (verdict_present, negation, logical connectives), and multiplication expressions. The harness is ready for orchestrator wiring in Plan 02.
</success_criteria>

<output>
After completion, create `.planning/phases/01.1-spec-ci-ai-ambiguity-testing/01.1-01-SUMMARY.md`
</output>
