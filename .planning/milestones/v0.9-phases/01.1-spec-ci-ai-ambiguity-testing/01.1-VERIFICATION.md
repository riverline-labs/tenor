---
phase: 01.1-spec-ci-ai-ambiguity-testing
verified: 2026-02-21T18:30:00Z
status: passed
score: 11/11 must-haves verified
re_verification: false
---

# Phase 01.1: Spec CI — AI Ambiguity Testing Verification Report

**Phase Goal:** A Rust-based CI harness feeds the frozen v1.0 spec + sample contracts to a frontier LLM, asks it to evaluate against sample facts, and compares verdicts against ground truth from the elaborator — catching spec ambiguities before the CLI and evaluator are built on top of it
**Verified:** 2026-02-21T18:30:00Z
**Status:** passed
**Re-verification:** No — initial verification

---

## Goal Achievement

### Observable Truths

| # | Truth | Status | Evidence |
|---|-------|--------|----------|
| 1 | ureq HTTP client can POST to Anthropic Messages API and deserialize typed Rust structs | VERIFIED | `api.rs` line 104: `agent.post(ANTHROPIC_API_URL)` with x-api-key header; `MessagesResponse` deserialized via `read_json()`; `cargo tree \| grep tokio` returns empty |
| 2 | Verdict comparison produces symmetric set difference with missing and extra sets | VERIFIED | `compare.rs` `compare_verdicts()`: BTreeSet difference ops produce `missing` and `extra`; 3 unit tests pass including `test_compare_missing_and_extra` |
| 3 | Report output emits TAP-format lines with YAML diagnostic blocks for mismatches | VERIFIED | `report.rs` `print_tap()`: emits "TAP version 14", "1..N" plan, "ok/not ok" lines, YAML blocks with missing_verdicts/extra_verdicts/llm_confidence/ambiguities_noted/reasoning_excerpt |
| 4 | Prompt builder injects spec sections, contract source, facts, and evaluation instructions | VERIFIED | `prompt.rs` `build_system_prompt()` extracts sections 4,7,10,12 from TENOR.md by heading regex; `build_user_prompt()` formats contract + facts + JSON schema instructions; 5 unit tests pass |
| 5 | Synthetic fact sets cover all-satisfied, partial, and none-satisfied scenarios | VERIFIED | 16 fixture files in `conformance/ambiguity/`: rule_basic (3 scenarios), integration_escrow (3 scenarios), rule_mul_valid (2 scenarios) — all contain valid JSON |
| 6 | Fixture loader reads .tenor source, .facts.json, and .verdicts.json triplets | VERIFIED | `fixtures.rs` `load_test_cases()`: scans `*.facts.json`, derives contract name, reads corresponding `.tenor` from `conformance/positive/`, loads `.verdicts.json`; all 3 source contracts exist |
| 7 | `tenor-elaborator ambiguity` subcommand is wired end-to-end in main.rs | VERIFIED | `main.rs` line 61: `"ambiguity" =>` arm calls `ambiguity::run_ambiguity_suite()`; usage message includes ambiguity subcommand |
| 8 | Without ANTHROPIC_API_KEY, command prints skip message and exits 0 | VERIFIED | Manually run: `cargo run -- ambiguity ../conformance` without key prints "# Skipping ambiguity tests: ANTHROPIC_API_KEY not set" and exits 0 |
| 9 | LLM verdict mismatches are informational (exit 0); hard errors (API failure, missing files) cause exit 1 | VERIFIED | `mod.rs` returns `AmbiguityRunResult.hard_errors`; `main.rs` line 124: `if result.hard_errors > 0 { process::exit(1) }` — mismatches do not set exit code |
| 10 | Existing 47 conformance tests are unaffected | VERIFIED | `cargo run -- run ../conformance` reports 47 pass / 0 fail |
| 11 | No async runtime introduced | VERIFIED | `cargo tree \| grep tokio` returns empty; ureq v3 is synchronous |

**Score:** 11/11 truths verified

---

### Required Artifacts

| Artifact | Expected | Status | Details |
|----------|----------|--------|---------|
| `elaborator/src/ambiguity/api.rs` | Anthropic API client with retry | VERIFIED | Contains `fn call_anthropic`, `fn with_retry`, `fn is_retryable`; exponential backoff on 429/500/503 |
| `elaborator/src/ambiguity/prompt.rs` | Prompt construction from spec + contract + facts | VERIFIED | Contains `fn build_system_prompt`, `fn build_user_prompt`, `fn extract_spec_sections` |
| `elaborator/src/ambiguity/compare.rs` | Verdict set comparison with symmetric difference | VERIFIED | Contains `fn compare_verdicts`, `fn parse_llm_response`; handles markdown code fences |
| `elaborator/src/ambiguity/report.rs` | TAP-format ambiguity reporting | VERIFIED | Contains `fn print_tap`, `fn summary`, `fn ambiguity_signals`, `fn add_result` |
| `elaborator/src/ambiguity/fixtures.rs` | Test case loader | VERIFIED | Contains `fn load_test_cases`, `fn derive_contract_name`, `fn contract_dir_for` |
| `elaborator/src/ambiguity/mod.rs` | Orchestrator + shared types | VERIFIED | Contains `fn run_ambiguity_suite`, `AmbiguityTestCase`, `AmbiguityResult`, `AmbiguityRunResult`; all submodules declared |
| `conformance/ambiguity/rule_basic_all_satisfied.facts.json` | All-satisfied fact set | VERIFIED | Valid JSON with is_active, balance, credit_limit, line_items |
| `conformance/ambiguity/escrow_release_approved.facts.json` | Escrow release fact set | VERIFIED | Valid JSON with delivery_status="confirmed", compliance_threshold |
| All 16 fixture files (8 facts + 8 verdicts) | Synthetic test cases | VERIFIED | All 16 files present in `conformance/ambiguity/`; each `.verdicts.json` has `{"verdicts": [...]}` array |

---

### Key Link Verification

| From | To | Via | Status | Details |
|------|----|-----|--------|---------|
| `main.rs` | `ambiguity/mod.rs` | `ambiguity::run_ambiguity_suite` call in match arm | WIRED | Line 117: `let result = ambiguity::run_ambiguity_suite(&suite_dir, &spec_path, model.as_deref())` |
| `mod.rs` | `api.rs` | `api::call_anthropic` per test case | WIRED | Line 146: `api::call_anthropic(&api_key, &system_prompt, &user_prompt, model_name)` |
| `mod.rs` | `fixtures.rs` | `fixtures::load_test_cases` to get all fixtures | WIRED | Line 93: `fixtures::load_test_cases(&ambiguity_dir, suite_dir)` |
| `mod.rs` | `prompt.rs` | `prompt::build_system_prompt` and `prompt::build_user_prompt` | WIRED | Lines 120, 143: both functions called per-case |
| `mod.rs` | `compare.rs` | `compare::compare_verdicts` and `compare::parse_llm_response` | WIRED | Lines 162, 178: both functions called per test case |
| `mod.rs` | `report.rs` | `report::AmbiguityReport`, `add_result`, `print_tap` | WIRED | Lines 136, 209, 213: report initialized, results added, TAP printed |
| `api.rs` | `https://api.anthropic.com/v1/messages` | ureq POST with x-api-key header | WIRED | `ANTHROPIC_API_URL` constant + `agent.post(ANTHROPIC_API_URL).header("x-api-key", api_key)` |
| `fixtures.rs` | `conformance/ambiguity/*.facts.json` | `load_test_cases` file-system scan | WIRED | `read_dir(ambiguity_dir)` + `.facts.json` filter + `serde_json::from_str` |
| `prompt.rs` | `docs/TENOR.md` | `build_system_prompt` reads spec by path | WIRED | `std::fs::read_to_string(spec_path)` + `extract_spec_sections` |

---

### Requirements Coverage

| Requirement | Source Plans | Description | Status | Evidence |
|-------------|-------------|-------------|--------|----------|
| SPEC-05 | 01.1-01-PLAN, 01.1-02-PLAN | Each spec change run through CFFP before implementation | SATISFIED (with note) | SPEC-05 was already marked Complete in Phase 1 (CFFP runs). Phase 1.1 extends this by providing a programmatic spec validation tool — the ambiguity harness is the tooling that enables ongoing CFFP-style verification. The harness is fully implemented and operational. |

**Note on SPEC-05 alignment:** REQUIREMENTS.md formally defines SPEC-05 as "CFFP process runs for SPEC-01/02/03 before implementation" — that process completed in Phase 1. Both Phase 1.1 plans claim SPEC-05 as their requirement ID, which is an imprecise mapping: the harness delivers a new capability (automated ambiguity detection) rather than satisfying a CFFP process milestone. However, the harness goal is fully achieved regardless of which requirement ID it should map to. No new requirement ID was defined in REQUIREMENTS.md for the ambiguity harness capability itself. This is a documentation inconsistency, not a code gap.

---

### Anti-Patterns Found

| File | Lines | Pattern | Severity | Impact |
|------|-------|---------|----------|--------|
| `elaborator/src/ambiguity/mod.rs` | 26 | `spec_sections` field never read (compiler warning) | Info | Field populated as empty vec in fixtures.rs, but unused. Does not block functionality. |
| `elaborator/src/ambiguity/mod.rs` | 41-43 | `total`, `matches`, `mismatches` fields never read (compiler warning) | Info | AmbiguityRunResult fields accessible but not used by main.rs (only `hard_errors` is checked). Does not block goal. |
| `elaborator/src/ambiguity/compare.rs` | 11,13 | `missing`, `extra` fields never read externally (compiler warning) | Info | Comparison is done via BTreeSet equality in report.rs, not via VerdictComparison struct fields. Struct is internally redundant with report.rs logic. Does not block TAP output. |
| `elaborator/src/ambiguity/report.rs` | 104 | `ambiguity_signals()` never called (compiler warning) | Info | Public API method exists but has no caller. Utility for future use. Does not block goal. |

All 4 warnings are `dead_code` warnings. None block goal achievement. Build produces 4 warnings but zero errors.

---

### Human Verification Required

#### 1. Live LLM Evaluation Quality

**Test:** Set `ANTHROPIC_API_KEY` and run `cd elaborator && cargo run -- ambiguity ../conformance`
**Expected:** TAP output for 8 test cases; at minimum some "ok" matches indicating LLM correctly evaluates rule logic from spec; any "not ok" results should have informative YAML diagnostics identifying genuine spec ambiguity signals
**Why human:** LLM response quality, reasoning clarity, and whether ambiguities flagged are genuine vs. noise cannot be verified without actually calling the API. The harness plumbing is correct — whether the prompt is effective enough to get accurate LLM verdicts is a runtime quality question.

#### 2. Spec Section Extraction Coverage

**Test:** Review system prompt generated by `build_system_prompt` when given actual `docs/TENOR.md` (sections 4, 7, 10, 12)
**Expected:** Extracted sections cover BaseType/TypeDecl, Rule evaluation semantics, PredicateExpression, and NumericModel — giving the LLM enough context to evaluate stratum 0/1 rules, Money comparisons, and multiplication expressions
**Why human:** Whether sections 4, 7, 10, 12 are the correct and sufficient spec sections for verdict evaluation requires reading TENOR.md and evaluating coverage judgment — this is a content decision, not a structural one.

---

### Gaps Summary

No gaps found. All six Rust source modules exist with substantive implementation (not stubs). All 16 fixture files are present with valid JSON. The full end-to-end pipeline is wired: fixture loading → prompt construction → API call with retry → verdict comparison → TAP report. The CLI subcommand is reachable, gracefully skips without an API key (exit 0), and distinguishes hard errors from informational mismatches. Existing 47 conformance tests pass unchanged.

The only notable finding is 4 compiler warnings for unused fields/methods — all are informational dead code in the public API surface, none affect runtime behavior or goal achievement.

---

_Verified: 2026-02-21T18:30:00Z_
_Verifier: Claude (gsd-verifier)_
